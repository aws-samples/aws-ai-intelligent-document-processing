{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify and Summarize documents in your IDP workflow with generative AI using Amazon Bedrock\n",
    "---\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <b>NOTE:</b>This notebook contains dependancies that are installed in a different notebook. Be sure that you have previously run the library install scripts at the top of 01-idp-genai-introduction and restart the kernel before executing this script.  \n",
    "</div>\n",
    "\n",
    "In this notebook, you will learn how to leverage Amazon Bedrock, a service that provides access to advanced foundation models, for intelligent document processing (IDP) tasks. IDP has become increasingly important for businesses as they seek to extract valuable insights from their documents and streamline document-centric processes.\n",
    "\n",
    "You will explore two key IDP use cases: document classification and document summarization. Document classification involves categorizing documents based on their content, enabling efficient routing and processing. Document summarization, on the other hand, aims to generate concise summaries of lengthy documents, allowing for quick understanding of their contents.\n",
    "\n",
    "Throughout the notebook, you will see how Amazon Bedrock's powerful multimodal capabilities, combined with Rhubarb, an open-source library, can simplify and accelerate IDP workflows. Rhubarb provides a user-friendly interface for interacting with Bedrock's models, abstracting away the complexities of prompt engineering and model invocation.\n",
    "\n",
    "By the end of this notebook, you will have gained hands-on experience in leveraging Amazon Bedrock and Rhubarb for document classification and summarization tasks, paving the way for more efficient and intelligent document processing in your organization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "---\n",
    "First, the necessary libraries and global variables are imported and initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import script libraries and create global variables\n",
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from bedrockhelper import get_response_from_claude\n",
    "from textractor.parsers import response_parser\n",
    "from textractor import Textractor\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "session = boto3.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "data_bucket = sagemaker.Session().default_bucket()\n",
    "region = sagemaker.Session().boto_region_name\n",
    "extractor = Textractor(region_name=region)\n",
    "print(f\"SageMaker bucket is {data_bucket}, and SageMaker Execution Role is {role}. Current region is {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Document Classification\n",
    "---\n",
    "To classify documents, the text is first extracted from the document and parsed into a format suitable for processing with a Foundation Models (FMs). This is done by uploading a multi-page PDF to Amazon S3 and using the Textractor library to call Amazon Textract, parse the results, and store them. Textractor utilizes the asynchronous processing capability of Textract for multi-page documents and waits for the processing to complete before returning the results.\n",
    "\n",
    "Textractor provides a summary of the content for each page of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "samples_file_name = 'samples/Sample1.pdf'\n",
    "\n",
    "# first we upload the file to S3\n",
    "s3.upload_file(Filename='../' + samples_file_name, Bucket=data_bucket, Key=samples_file_name)\n",
    "\n",
    "document = extractor.start_document_text_detection(file_source=\"s3://\" + data_bucket + \"/\" + samples_file_name,\n",
    "    save_image=False)\n",
    "\n",
    "print(document.pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize each page\n",
    "---\n",
    "The Claude FM from Anthropic can classify a document based on its content, given a list of classes. The code demonstrates how to format a prompt for Claude to classify each page of the document into one of the specified classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(doc_text):\n",
    "    return f\"\"\"\n",
    "\n",
    "Given the document\n",
    "\n",
    "<document>{doc_text}<document>\n",
    "\n",
    "classify the document into the following classes\n",
    "\n",
    "<classes>\n",
    "DRIVERS_LICENSE\n",
    "INSURANCE_ID\n",
    "RECEIPT\n",
    "BANK_STATEMENT\n",
    "W2\n",
    "MEETING_MINUTES\n",
    "</classes>\n",
    "\n",
    "\n",
    "\n",
    "return only the CLASS_NAME with no preamble or explination. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for page in document.pages:\n",
    "    prompt = format_prompt(page.get_text())\n",
    "    response = get_response_from_claude(prompt)\n",
    "    print(f\"\"\"Page {page.page_num} is class {response[0]}. There were {response[1]} input tokens and {response[2]} output tokens used.\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Multimodal capabilities of Amazon Bedrock\n",
    "The Claude 3 models are multimodal, meaning they can accept both text and images as input. Rhubarb is an open-source library that makes it easy to build IDP solutions using the multimodal capabilities of Bedrock.\n",
    "\n",
    "The code shows how to use Rhubarb's `ClassificationSysPrompt` system prompt for single-class classification and `MultiClassificationSysPrompt` system prompt for multi-class classification of document pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rhubarb import DocAnalysis, SystemPrompts, LanguageModels\n",
    "\n",
    "\n",
    "da = DocAnalysis(file_path=\"../samples/Sample1.pdf\", \n",
    "                 boto3_session=session,\n",
    "                 modelId=LanguageModels.CLAUDE_HAIKU_V1,\n",
    "                 system_prompt=SystemPrompts().ClassificationSysPrompt)\n",
    "resp = da.run(message=\"\"\"Given the document, classify the pages into the following classes\n",
    "                        <classes>\n",
    "                        DRIVERS_LICENSE  # a driver's license\n",
    "                        INSURANCE_ID     # a medical insurance ID card\n",
    "                        RECEIPT          # a store receipt\n",
    "                        BANK_STATEMENT   # a bank statement\n",
    "                        W2               # a W2 tax document\n",
    "                        MOM              # a minutes of meeting or meeting notes\n",
    "                        </classes>\"\"\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or multi-class classification. Note that in Multi-class classification it is helpful to clarify the hierarchy of classes to the model in two different list of classes. This should typically match with your document taxonomy such as\n",
    "\n",
    "```\n",
    "FINANCIAL           (Level-2)\n",
    "├── BANK_STATEMENT  (Level-1 leaf)\n",
    "└── W2              (Level-1 leaf)\n",
    "\n",
    "IDENTIFICATION      (Level-2)\n",
    "├── DRIVERS_LICENSE (Level-1 leaf)\n",
    "└── INSURANCE_ID    (Level-1 leaf)\n",
    "```\n",
    "\n",
    "And so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = DocAnalysis(file_path=\"../samples/Sample1.pdf\", \n",
    "                 boto3_session=session,\n",
    "                 modelId=LanguageModels.CLAUDE_HAIKU_V1,\n",
    "                 system_prompt=SystemPrompts().MultiClassificationSysPrompt)\n",
    "resp = da.run(message=\"\"\"Given the document, classify the pages into the following classes\n",
    "                        <classes_level1>\n",
    "                        DRIVERS_LICENSE  # a driver's license\n",
    "                        INSURANCE_ID     # a medical insurance ID card\n",
    "                        RECEIPT          # a store receipt\n",
    "                        BANK_STATEMENT   # a bank statement\n",
    "                        W2               # a W2 tax document\n",
    "                        MOM              # a minutes of meeting or meeting notes\n",
    "                        <classes_level1>\n",
    "                        <classes_level2>\n",
    "                        FINANCIAL        # a document related to finances of a person\n",
    "                        IDENTIFICATION   # a personal document such as ID, membership cards, etc.\n",
    "                        GENERAL          # any other general document\n",
    "                        </classes_level2>\"\"\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document Summarization\n",
    "---\n",
    "\n",
    "Bedrock FMs are well-suited for summarizing document contents into a concise and readable format. The code demonstrates how to upload a PDF document to Amazon S3, extract its text using Textractor, and prompt the FMs to summarize the document at different levels (page-level and whole document).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we upload the file to S3\n",
    "employee_file_name = 'samples/employee_enroFMsent.pdf'\n",
    "s3.upload_file(Filename='../' + employee_file_name, Bucket=data_bucket, Key=employee_file_name)\n",
    "\n",
    "document = extractor.start_document_text_detection(file_source=\"s3://\" + data_bucket + \"/\" + employee_file_name,\n",
    "    save_image=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform page level summarization\n",
    "---\n",
    "We can loop through each page of results and ask for a page level summary. This will create a summary of the document per page which will be helpful if different pages contain discrete information that has to be summarized individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(doc_text):\n",
    "    return f\"\"\"\n",
    "\n",
    "Given the document\n",
    "\n",
    "<document>{doc_text}<document>\n",
    "\n",
    "Give me a 50 word summary of this document that can be shown alongside search results. \n",
    "\n",
    "Return only the summary text with no preamble. \n",
    "\"\"\"\n",
    "\n",
    "for page in document.pages:\n",
    "    prompt = format_prompt(page.get_text())\n",
    "    response = get_response_from_claude(prompt)\n",
    "    print(f\"\"\"Page {page.page_num} Summary:\\n{response[0]}\\nThere were {response[1]} input tokens and {response[2]} output tokens used.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the whole document\n",
    "---\n",
    "We can also pass the complete text in for a single summarization. This helps users summarize the entire document at once which can be useful for generating summaries of larger documents such as research papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(doc_text):\n",
    "    return f\"\"\"\n",
    "\n",
    "Given the document\n",
    "\n",
    "<document>{doc_text}<document>\n",
    "\n",
    "Give me a 50 word summary of this document that can be shown alongside search results. \n",
    "\n",
    "Return only the summary text with no preamble. \n",
    "\"\"\"\n",
    "\n",
    "prompt = format_prompt(document.get_text())\n",
    "response = get_response_from_claude(prompt)\n",
    "print(f\"\"\"Summary:\\n{response[0]}\\nThere were {response[1]} input tokens and {response[2]} output tokens used.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization using Bedrock multi-modal capibilities\n",
    "The Claude 3 family of models support both images and text as imput. \n",
    "\n",
    "Rhubarb can generate sumarries of every page in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "session = boto3.Session()\n",
    "from rhubarb import DocAnalysis\n",
    "\n",
    "da = DocAnalysis(file_path=\"../samples/employee_enroFMsent.pdf\", \n",
    "                 modelId=LanguageModels.CLAUDE_HAIKU_V1,\n",
    "                 boto3_session=session)\n",
    "resp = da.run(message=\"Give me a brief summary for each page.\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform full summarization\n",
    "---\n",
    "Or you can generate an overall summary of the entire document. In this case, we will override the default System Prompt which breaks down the response per page. Rhubarb comes with a Summary specific System Prompt for the model, available via `SystemPrompts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rhubarb import SystemPrompts\n",
    "\n",
    "da = DocAnalysis(file_path=\"../samples/employee_enroFMsent.pdf\", \n",
    "                 boto3_session=session,\n",
    "                 modelId=LanguageModels.CLAUDE_HAIKU_V1,\n",
    "                 system_prompt=SystemPrompts().SummarySysPrompt)\n",
    "resp = da.run(message=\"Give me a brief summary of this document.\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform summarization of specific pages\n",
    "---\n",
    "You can also perform summarization of specific pages using the `pages` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = DocAnalysis(file_path=\"../samples/employee_enroFMsent.pdf\", \n",
    "                 boto3_session=session,\n",
    "                 modelId=LanguageModels.CLAUDE_HAIKU_V1,\n",
    "                 system_prompt=SystemPrompts().SummarySysPrompt,\n",
    "                 pages=[1,3])\n",
    "resp = da.run(message=\"Give me a brief summary of this document.\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming summaries\n",
    "---\n",
    "In some cases, you may want to stream the summaries for example let's say a real time chat application. You can easily do that using the `run_stream` method. Let's generate the full summary and stream it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = DocAnalysis(file_path=\"../samples/employee_enroFMsent.pdf\", \n",
    "                 boto3_session=session,\n",
    "                 modelId=LanguageModels.CLAUDE_HAIKU_V1,\n",
    "                 system_prompt=SystemPrompts().SummarySysPrompt)\n",
    "for resp in da.run_stream(message=\"Give me a brief summary of this document.\"):\n",
    "    if isinstance(resp, str):\n",
    "        print(resp,end='')\n",
    "    else:\n",
    "        print(\"\\n\")\n",
    "        print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "---\n",
    "Finally, the code demonstrates how to clean up by deleting the sample files uploaded to Amazon S3 earlier in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.delete_object(Bucket=data_bucket, Key=samples_file_name)\n",
    "s3.delete_object(Bucket=data_bucket, Key=employee_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
