{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f6e38fc-9f24-4c8f-9e2e-2c120eb68d45",
   "metadata": {},
   "source": [
    "# Unlocking the Power of Intelligent Document Processing with Amazon Textract and Amazon Bedrock\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <b>NOTE:</b> If you are using SageMaker studio <b>classic</b> will need to use a Jupyter Kernel with Python 3.9 or above to use this notebook. If you are in Amazon SageMaker Studio, you can use the `Data Science 3.0` image.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "    <b>NOTE:</b> You will need 3rd party model access to Anthropic Claude 3 Sonnet and Haiku models to be able to run this notebook. Verify if you have access to the model by going to <a href=\"https://console.aws.amazon.com/bedrock\" target=\"_blank\">Amazon Bedrock console</a> > left menu \"Model access\". The \"Access status\" for Anthropic Claude must be in \"Access granted\" status in green. If you do not have access, then click \"Edit\" button on the top right > select the model checkbox > click \"Save changes\" button at the bottom. You should have access to the model within a few moments.\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "---------------\n",
    "In this notebook, we will explore the powerful capabilities of Amazon Textract and Amazon Bedrock for intelligent document processing (IDP). IDP involves automatically extracting valuable information from documents, enabling organizations to streamline document-centric workflows, reduce operational costs, and gain insights from their data.\n",
    "\n",
    "Amazon Textract uses advanced machine learning and computer vision technologies to accurately extract text, data, and metadata from various document formats, including PDFs, images, and scanned documents. By automating this process, Textract eliminates the need for manual data entry, increasing efficiency and reducing the risk of errors.\n",
    "\n",
    "Amazon Bedrock, on the other hand, provides access to state-of-the-art foundation models (FMs) that can understand and process both text and visual data. These multi-modal models can accurately identify and extract relevant information from structured, semi-structured, and unstructured documents, enabling tasks such as form extraction, table extraction, and intelligent question answering.\n",
    "\n",
    "Together, Textract and Bedrock form a powerful combination for building intelligent document processing pipelines. Textract handles the initial document ingestion and text extraction, while Bedrock's FMs provide advanced understanding and extraction capabilities.\n",
    "\n",
    "Throughout this notebook, we will explore the key features of both services and learn how to integrate them into your workflows using Python libraries like Textractor and Rhubarb. By the end of this notebook, you will have a solid understanding of how to leverage AWS for efficient and accurate document processing, enabling your organization to unlock valuable insights from its data assets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d9e90",
   "metadata": {},
   "source": [
    "## Basic building blocks\n",
    "---\n",
    "This lab is an introduction to the libraries and interfaces used in subsequent intelligent document processing with generative AI labs. It introduces the key libraries that will be used, along with providing code samples that you can modify in your own workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b0ee4-b856-4718-992e-99390f56068e",
   "metadata": {},
   "source": [
    "### Setup Prerequisites\n",
    "---\n",
    "\n",
    "First we need to \n",
    "1. Install Textractor. This open source python library makes it easy to parse and handle the JSON output from Amazon Textract\n",
    "2. Install Rhubarb. This open source python ligrary makes it easy to use Amazon Bedrock multimodal capibiliteis for IDP\n",
    "3. Install Sagemaker to give you access to a SageMaker session context which will in turn give you access to the default S3 storage buckets from SageMaker notebook environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c12c62-2259-48b9-8148-70a540c28ae5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install \"amazon-textract-textractor[pdf]\"\n",
    "%pip install pyrhubarb\n",
    "%pip install -U boto3\n",
    "\n",
    "%pip install -q amazon-textract-response-parser --upgrade\n",
    "%pip install -q amazon-textract-caller --upgrade\n",
    "%pip install -q amazon-textract-prettyprinter==0.0.16\n",
    "%pip install -q amazon-textract-textractor --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd886e-d953-4b0e-81a1-54d72847b8f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import script libraries and create global variables\n",
    "import json\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display, JSON\n",
    "from textractcaller.t_call import call_textract, Textract_Features, call_textract_expense\n",
    "from textractprettyprinter.t_pretty_print import convert_table_to_list\n",
    "from trp import Document\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "data_bucket = sagemaker.Session().default_bucket()\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(f\"SageMaker bucket is {data_bucket}, and SageMaker Execution Role is {role}. Current region is {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f216317d",
   "metadata": {},
   "source": [
    "### Use Boto3 to call the Bedrock API\n",
    "---\n",
    "Sending a prompt directly to Bedrock with Boto3 is easy and gives fine grain control over your prompt and parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc12a4-44de-4352-84b9-3218813fe731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "bedrock = boto3.client(service_name=\"bedrock-runtime\", region_name=region)\n",
    "\n",
    "#Create a global function to call Bedrock. \n",
    "def get_response_from_claude(prompt, temp=1, model='sonnet'):\n",
    "\t\"\"\"\n",
    "\tInvokes Anthropic Claude 3 Haiku to run a text inference using the input\n",
    "\tprovided in the request body.\n",
    "\n",
    "\t:param prompt:  The prompt that you want Claude 3 to use.\n",
    "\t:param temp:    The temperature to use when invoking Claude. Default is 1\n",
    "\t:param model:   The claude model to use. Currently this supports haiku and sonnet. Default is Sonnett\n",
    "\t:return:        Text response, input token count, output token count\n",
    "\t\"\"\"\n",
    "\n",
    "\t# Invoke the model with the prompt and the encoded image\n",
    "\tmodel_dict = {\n",
    "        \"haiku\":\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "        \"sonnet\":\"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    }\n",
    "\tmodel_id = model_dict[model]\n",
    "\trequest_body = {\n",
    "\t\t\"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "\t\t\"max_tokens\": 4096,\n",
    "        \"temperature\":temp,\n",
    "\t\t\"messages\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"role\": \"user\",\n",
    "\t\t\t\t\"content\": [\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\t\t\"text\": prompt,\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t],\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t}\n",
    "\n",
    "\ttry:\n",
    "\t\tresponse = bedrock.invoke_model(\n",
    "\t\t\tmodelId=model_id,\n",
    "\t\t\tbody=json.dumps(request_body),\n",
    "\t\t)\n",
    "\n",
    "\t\t# Process and print the response\n",
    "\t\tresult = json.loads(response.get(\"body\").read())\n",
    "\t\tinput_tokens = result[\"usage\"][\"input_tokens\"]\n",
    "\t\toutput_tokens = result[\"usage\"][\"output_tokens\"]\n",
    "\n",
    "\t\t# the current Bedrock Claude Messagees API only supports text content in responses\n",
    "\t\ttext_response = result[\"content\"][0][\"text\"]\n",
    "\n",
    "        # return a tuple with 3 values\n",
    "\t\treturn text_response, input_tokens, output_tokens\n",
    "\texcept ClientError as err:\n",
    "\t\tprint(\n",
    "\t\t\tF\"Couldn't invoke model Here's why: {err.response['Error']['Code']}: {err.response['Error']['Message']}\"\n",
    "\t\t)\n",
    "\t\traise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473739b5",
   "metadata": {},
   "source": [
    "Now we'll verify that the models can be called, try changing the prompt and model below between sonnet and haiku. If you see an error code verify that you have [requested access](https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html#getting-started-model-access) for the chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ffff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_response_from_claude(\"Tell me a short story\", temp=1, model='sonnet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1585e7-0776-4482-b89d-78f348504925",
   "metadata": {},
   "source": [
    "### 1. Basic usage with Amazon Textract and Amazon Textractor\n",
    "---\n",
    "This code block demonstrates how to use the Amazon Textract service directly through the AWS SDK for Python (Boto3) to extract text from a document stored in an Amazon S3 bucket. It first uploads the document to S3, then calls the `detect_document_text` method of the Textract client to perform text detection on the document. The response from Textract is then parsed using the `textractor.parsers.response_parser` module to create a more user-friendly representation of the detected text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9093a6-ce0f-481e-8d82-14a07a860191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from textractor.parsers import response_parser\n",
    "\n",
    "textract = boto3.client('textract')\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# first we upload the file to S3\n",
    "s3.upload_file(Filename='../samples/discharge-summary.png', Bucket=data_bucket, Key='samples/discharge-summary.png')\n",
    "\n",
    "# next We will use the Textract detect document text action to get all the text in the document.\n",
    "textract_response = textract.detect_document_text(\n",
    "    Document={'S3Object': \n",
    "              {'Bucket': data_bucket,'Name': 'samples/discharge-summary.png'}\n",
    "             }, \n",
    "\t)\n",
    "\t\n",
    "# Textractor provides a parser to give us a summary of the contents and a string with the detected text\n",
    "document = response_parser.parse(textract_response)\n",
    "\n",
    "# the document object contains a summary of what textract returned \n",
    "print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edf818d",
   "metadata": {},
   "source": [
    "### Extracting tabular data using Amazon Textract\n",
    "\n",
    "In this step we will take a brief look at how to extract table information from the bank statements. Our bank statement has two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dbb24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = textract.analyze_document(\n",
    "    Document={\n",
    "        'S3Object': {\n",
    "            'Bucket': data_bucket,\n",
    "            'Name': 'samples/discharge-summary.png'\n",
    "        }\n",
    "    },\n",
    "    FeatureTypes=[\"TABLES\"])\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2dba59",
   "metadata": {},
   "source": [
    "As you can see, the response from Amazon Textract is a large JSON object that contains a lot of information. Let's parse out the table data from this response. To do this, we will see how to extract the tables using the textract response parser tool that we installed earlier. To learn about how Textract Table response works, refer to the documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac6eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(response)\n",
    "doc = Document(response)\n",
    "for page in doc.pages:\n",
    "     # Print tables\n",
    "    for table in page.tables:\n",
    "        for r, row in enumerate(table.rows):\n",
    "            for c, cell in enumerate(row.cells):\n",
    "                print(\"Table[{}][{}] = {}\".format(r, c, cell.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045fab92",
   "metadata": {},
   "source": [
    "In the code cells above, we used the Textract AnalyzeDocument API to extract info from the document and subsequently used textract response parser Document to parse out the tables from the JSON response. We can further use additional tooling to call the Textract API and use textract pretty printer tool to view the tables in a slightly more human readable way. We will see how to extract the tables using the Textract pretty printer tool. We will also use call_textract method from the Textract Caller tool that we installed earlier. These set of tools make it easy for us to make Textract API calls and parse it's JSON output. In our subsequent sections, we will make use of these tools to make API calls and subsequently to parse the JSON response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'samples/account_statement.png'\n",
    "resp = call_textract(input_document=file, features=[Textract_Features.TABLES])\n",
    "tdoc = Document(resp)\n",
    "dfs = list()\n",
    "\n",
    "for page in tdoc.pages:\n",
    "    for table in page.tables:\n",
    "        tab_list = convert_table_to_list(trp_table=table)\n",
    "        print(tab_list)\n",
    "        dfs.append(pd.DataFrame(tab_list))\n",
    "\n",
    "df1 = dfs[0]\n",
    "df2 = dfs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31298f97",
   "metadata": {},
   "source": [
    "In the code cell above, we extracted the tables as a Python List and then converted them to Pandas DataFrame. You can also extract tables in other formats such as CSV, TSV etc. Refer to the PrettyPrinter documentation for more. Now let's look at the DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b69fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb26ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f2345a",
   "metadata": {},
   "source": [
    "### Using the Textractor library\n",
    "---\n",
    "This library provides a higher-level interface for working with Amazon Textract. Instead of calling Textract directly, you can use Textractor's caller methods [caller methods](https://aws-samples.github.io/amazon-textract-textractor/textractor.html) method, which abstracts away some of the complexities of interacting with the Textract service. In this example, Textractor is used to extract text from a document stored in an S3 bucket.\n",
    "\n",
    "For the first example below, we are using Amazon Textract's [synchronous API](https://docs.aws.amazon.com/textract/latest/dg/sync.html) which will allow u to quickly analyze a **single page** of a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf8eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textractor import Textractor\n",
    "extractor = Textractor(region_name=region)\n",
    "\n",
    "document = extractor.detect_document_text('s3://' + data_bucket + '/samples/discharge-summary.png')\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f448d",
   "metadata": {},
   "source": [
    "---\n",
    "You can also use Textractor to extract text from a local file on your machine, rather than a file stored in S3. This can be more convenient for smaller projects or local testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0ed3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textractor import Textractor\n",
    "extractor = Textractor(region_name=region)\n",
    "\n",
    "document = extractor.detect_document_text(\"../samples/discharge-summary.png\")\n",
    "print(document.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3b9dc",
   "metadata": {},
   "source": [
    "---\n",
    "Textractor also works with Textract's asynchronous methods, which are useful for processing multi-page documents. It first uploads a PDF file to S3, then calls Textractor's `start_document_text_detection` method to initiate an asynchronous text detection job. The results of this job are then printed out page by page.\n",
    "\n",
    "\n",
    "The asynchronous API helps us process large multi page documents without the application being blocked. The document is sent off to the endpoint and it'll automatically split, and parallelize the OCR detection across all of the pages without the application having to do it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85acfec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textractor import Textractor\n",
    "extractor = Textractor(region_name=region)\n",
    "\n",
    "# first we upload the file to S3\n",
    "s3.upload_file(Filename='../samples/employee_enrollment.pdf', Bucket=data_bucket, Key='samples/employee_enrollment.pdf')\n",
    "\n",
    "document = extractor.start_document_text_detection(file_source=\"s3://\" + data_bucket + \"/samples/employee_enrollment.pdf\",\n",
    "    save_image=False)\n",
    "\n",
    "for page in document.pages:\n",
    "    print(page)\n",
    "    print(\"\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed904147-9ed1-4db1-81ee-5a433624b204",
   "metadata": {},
   "source": [
    "---\n",
    "You can retrieve the full text content of the document from the Textractor `document` object, which can then be used as input for any further processing using the `get_text()` API call. For a full event driven workflow, you could also leverage Amazon Textract's [integration with SNS](https://docs.aws.amazon.com/textract/latest/dg/api-async-roles.html#api-async-roles-all-topics) to start additional processing workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9578d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"\\nDetected Text \\n=========================\\n\")\n",
    "doc_text = document.get_text()\n",
    "print(doc_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb476c1",
   "metadata": {},
   "source": [
    "### 2. Basic usage with Bedrock\n",
    "---\n",
    "Now we can use the Bedrock library to generate a response based on the document text extracted by Textractor. It constructs a prompt that includes the document text, and then calls a previously defined function `get_response_from_claude` to generate a response based on that prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67334979",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "\n",
    "Given the document\n",
    "\n",
    "<document>{doc_text}<document>\n",
    "\n",
    "What is the employee's name?\n",
    "\"\"\"\n",
    "\n",
    "response = get_response_from_claude(prompt)\n",
    "\n",
    "print (f\"Our prompt has {response[1]} input tokens and Claude returned {response[2]} output tokens \\n\\n=========================\\n\")\n",
    "print(response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd3649a",
   "metadata": {},
   "source": [
    "### 3. Basic usage with Rhubarb\n",
    "---\n",
    "\n",
    "The Rhubarb library, which provides a high-level interface for using Bedrock's multi-modal models (models that can process both text and images/documents). It demonstrates how to create a `DocAnalysis` object with a local PDF file, and then use that object to generate a response to a textual query using one of Bedrock's multi-modal models.\n",
    "\n",
    "\n",
    "Rhubarb under the hood will make use of pdfplumber to first read each page of the document, convert it into images before passing it into a multi modal model that will then analyze the image based and output the specified data in the prompt provided.  The DocAnalysis object wraps all of these tasks into a single function call.\n",
    "\n",
    "Compared to using Amazon Textract to first do the OCR followed ny the specific entity extraction, we do it in a single step with Rhubarb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb4152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "session = boto3.Session()\n",
    "from rhubarb import DocAnalysis, LanguageModels\n",
    "\n",
    "\n",
    "da = DocAnalysis(file_path=\"../samples/employee_enrollment.pdf\",\n",
    "                  modelId=LanguageModels.CLAUDE_HAIKU_V1,\n",
    "                  boto3_session=session)\n",
    "resp = da.run(message=\"What is the employee's name?\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497cb636-9ea2-4f3f-aa6e-a856574a2a17",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "---\n",
    "Let's delete the sample files we uploaded earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2d322-c0b9-4eec-b544-edf6d761b15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3.delete_object(Bucket=data_bucket, Key='samples/discharge-summary.png')\n",
    "s3.delete_object(Bucket=data_bucket, Key='samples/employee_enrollment.pdf')"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
